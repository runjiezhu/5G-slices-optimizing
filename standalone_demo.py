"""
5Gç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿç‹¬ç«‹æ¼”ç¤º
å®Œå…¨ç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–å¤æ‚çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
import random
from typing import Dict, List, Tuple
from dataclasses import dataclass
from enum import Enum


class SliceType(Enum):
    """ç½‘ç»œåˆ‡ç‰‡ç±»å‹"""
    eMBB = "å¢å¼ºå‹ç§»åŠ¨å®½å¸¦"
    URLLC = "è¶…å¯é ä½æ—¶å»¶é€šä¿¡"
    mMTC = "å¤§è§„æ¨¡æœºå™¨ç±»å‹é€šä¿¡"


@dataclass
class UserData:
    """ç”¨æˆ·æ•°æ®ç»“æ„"""
    user_id: str
    timestamp: datetime
    position: Tuple[float, float, float]
    velocity: Tuple[float, float, float]
    behavior: Dict[str, float]
    network_metrics: Dict[str, float]
    slice_type: str


class SimpleDataGenerator:
    """ç®€åŒ–çš„æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, seed: int = 42):
        np.random.seed(seed)
        random.seed(seed)
    
    def generate_user_data(self, num_users: int = 10, hours: int = 1) -> List[UserData]:
        """ç”Ÿæˆç”¨æˆ·æ•°æ®"""
        data_list = []
        start_time = datetime.now()
        
        for user_idx in range(num_users):
            user_id = f"user_{user_idx:03d}"
            
            # ç¡®å®šç”¨æˆ·ç±»å‹å’Œåå¥½
            user_type = random.choice(['business', 'personal', 'iot'])
            if user_type == 'business':
                preferred_slice = SliceType.URLLC.name
                activity_level = np.random.uniform(0.7, 1.0)
            elif user_type == 'personal':
                preferred_slice = SliceType.eMBB.name
                activity_level = np.random.uniform(0.4, 0.8)
            else:
                preferred_slice = SliceType.mMTC.name
                activity_level = np.random.uniform(0.1, 0.3)
            
            # ç”Ÿæˆè¯¥ç”¨æˆ·çš„æ—¶é—´åºåˆ—æ•°æ®
            num_points = hours * 60  # æ¯åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹
            
            # åˆå§‹ä½ç½®
            base_x = np.random.uniform(-50, 50)
            base_y = np.random.uniform(-50, 50)
            
            for minute in range(num_points):
                timestamp = start_time + timedelta(minutes=minute)
                
                # ä½ç½®ï¼ˆç®€å•çš„éšæœºæ¸¸èµ°ï¼‰
                noise_x = np.random.normal(0, 1.0)
                noise_y = np.random.normal(0, 1.0) 
                position = (
                    base_x + noise_x,
                    base_y + noise_y,
                    np.random.uniform(0, 2)  # é«˜åº¦
                )                
                # é€Ÿåº¦
                velocity = (
                    noise_x / 60,  # m/s
                    noise_y / 60,
                    np.random.normal(0, 0.1)
                )
                
                # è¡Œä¸ºç‰¹å¾
                hour = timestamp.hour
                behavior = {
                    'data_usage': np.random.lognormal(2, 1) * activity_level,
                    'call_duration': np.random.exponential(30) if np.random.random() < 0.2 else 0,
                    'app_video': 0.8 if hour >= 19 and hour <= 22 else 0.2,
                    'app_social': 0.6 if hour >= 8 and hour <= 23 else 0.1,
                    'app_work': 0.9 if hour >= 9 and hour <= 17 and user_type == 'business' else 0.1,
                    'is_peak_hour': 1.0 if (8 <= hour <= 10) or (17 <= hour <= 19) else 0.0
                }
                
                # ç½‘ç»œæŒ‡æ ‡
                distance_from_center = np.sqrt(position[0]**2 + position[1]**2)
                signal_strength = max(0.1, 1.0 - distance_from_center / 100.0)
                
                network_metrics = {
                    'signal_strength': signal_strength + np.random.normal(0, 0.1),
                    'latency': max(1, 10 + distance_from_center * 0.5 + np.random.exponential(5)),
                    'throughput': max(0.1, signal_strength * 100 * np.random.uniform(0.8, 1.2)),
                    'packet_loss': np.random.exponential(0.01),
                    'jitter': np.random.exponential(2.0)
                }
                
                data_point = UserData(
                    user_id=user_id,
                    timestamp=timestamp,
                    position=position,
                    velocity=velocity,
                    behavior=behavior,
                    network_metrics=network_metrics,
                    slice_type=preferred_slice
                )
                
                data_list.append(data_point)
        
        return data_list


def softmax(x):
    """Softmaxå‡½æ•°"""
    exp_x = np.exp(x - np.max(x))
    return exp_x / np.sum(exp_x)


def simulate_ai_prediction(features: np.ndarray) -> Dict:
    """æ¨¡æ‹ŸAIé¢„æµ‹"""
    num_users = features.shape[0]
    
    # æ¨¡æ‹ŸTransformeré¢„æµ‹
    slice_logits = np.random.randn(num_users, 3)  # 3ç§åˆ‡ç‰‡ç±»å‹
    slice_probs = np.array([softmax(logits) for logits in slice_logits])
    
    # å¸¦å®½éœ€æ±‚é¢„æµ‹
    bandwidth_pred = np.random.uniform(5, 200, num_users)
    
    # ç½®ä¿¡åº¦
    confidence = np.random.uniform(0.6, 0.95, num_users)
    
    return {
        'slice_probabilities': slice_probs,
        'bandwidth_demand': bandwidth_pred,
        'confidence': confidence
    }


def optimize_network_slices(predictions: Dict, user_data: List[UserData]) -> List[Dict]:
    """ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–"""
    allocations = []
    
    # æ€»èµ„æº
    total_bandwidth = 1000.0  # Mbps
    remaining_bandwidth = total_bandwidth
    
    slice_names = ['eMBB', 'URLLC', 'mMTC']
    slice_priorities = [1, 3, 2]
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºç”¨æˆ·
    user_priorities = []
    for i, user in enumerate(user_data):
        slice_idx = np.argmax(predictions['slice_probabilities'][i])
        priority = slice_priorities[slice_idx]
        user_priorities.append((priority, i, user))
    
    user_priorities.sort(key=lambda x: x[0], reverse=True)
    
    # åˆ†é…èµ„æº
    for priority, i, user in user_priorities:
        if remaining_bandwidth <= 0:
            break
        
        slice_idx = np.argmax(predictions['slice_probabilities'][i])
        slice_type = slice_names[slice_idx]
        
        # é¢„æµ‹å¸¦å®½éœ€æ±‚
        demanded_bandwidth = predictions['bandwidth_demand'][i]
        
        # åˆ†é…ç­–ç•¥
        if slice_type == 'URLLC':
            # é«˜ä¼˜å…ˆçº§ï¼Œä¿è¯æœ€å°å¸¦å®½
            allocated = min(max(demanded_bandwidth, 10), remaining_bandwidth)
        elif slice_type == 'eMBB':
            # ä¸­ä¼˜å…ˆçº§ï¼Œæ ¹æ®éœ€æ±‚å’Œå¯ç”¨æ€§
            allocated = min(demanded_bandwidth, remaining_bandwidth * 0.3)
        else:  # mMTC
            # ä½ä¼˜å…ˆçº§ï¼Œåˆ†é…è¾ƒå°‘å¸¦å®½
            allocated = min(demanded_bandwidth, remaining_bandwidth * 0.1, 20)
        
        remaining_bandwidth -= allocated
        
        # æ»¡æ„åº¦è®¡ç®—
        satisfaction = min(1.0, allocated / max(demanded_bandwidth, 1))
        
        allocation = {
            'user_id': user.user_id,
            'slice_type': slice_type,
            'allocated_bandwidth': allocated,
            'demanded_bandwidth': demanded_bandwidth,
            'satisfaction': satisfaction,
            'confidence': predictions['confidence'][i],
            'priority': priority
        }
        
        allocations.append(allocation)
    
    return allocations


def run_standalone_demo():
    """è¿è¡Œç‹¬ç«‹æ¼”ç¤º"""
    print("ğŸŒ 5GåŠ¨æ€ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿ - ç‹¬ç«‹æ¼”ç¤º")
    print("=" * 70)
    
    # 1. æ•°æ®ç”Ÿæˆ
    print("ğŸ“Š 1. ç”Ÿæˆ5Gç”¨æˆ·æ•°æ®...")
    generator = SimpleDataGenerator(seed=42)
    user_data = generator.generate_user_data(num_users=20, hours=2)
    
    print(f"   âœ… ç”Ÿæˆäº† {len(user_data)} æ¡æ•°æ®è®°å½•")
    print(f"   ğŸ‘¥ æ¶µç›– {len(set(d.user_id for d in user_data))} ä¸ªç”¨æˆ·")
    print(f"   â° æ—¶é—´è·¨åº¦: 2å°æ—¶")
    
    # 2. æ•°æ®åˆ†æ
    print("\nğŸ“ˆ 2. æ•°æ®ç»Ÿè®¡åˆ†æ...")
    
    # è½¬æ¢ä¸ºDataFrameä¾¿äºåˆ†æ
    records = []
    for data in user_data:
        record = {
            'user_id': data.user_id,
            'timestamp': data.timestamp,
            'pos_x': data.position[0],
            'pos_y': data.position[1],
            'slice_type': data.slice_type,
            'data_usage': data.behavior['data_usage'],
            'signal_strength': data.network_metrics['signal_strength'],
            'latency': data.network_metrics['latency'],
            'throughput': data.network_metrics['throughput']
        }
        records.append(record)
    
    df = pd.DataFrame(records)
    
    # åˆ‡ç‰‡ç±»å‹åˆ†å¸ƒ
    slice_dist = df['slice_type'].value_counts()
    print("   ğŸ”§ åˆ‡ç‰‡ç±»å‹åˆ†å¸ƒ:")
    for slice_type, count in slice_dist.items():
        print(f"     â€¢ {slice_type}: {count} ({count/len(df)*100:.1f}%)")
    
    # åŸºç¡€ç»Ÿè®¡
    print(f"   ğŸ“Š å¹³å‡æ•°æ®ä½¿ç”¨: {df['data_usage'].mean():.2f} MB")
    print(f"   ğŸ“¶ å¹³å‡ä¿¡å·å¼ºåº¦: {df['signal_strength'].mean():.3f}")
    print(f"   â±ï¸  å¹³å‡å»¶è¿Ÿ: {df['latency'].mean():.2f} ms")
    print(f"   ğŸš€ å¹³å‡ååé‡: {df['throughput'].mean():.2f} Mbps")
    
    # 3. ç”¨æˆ·è¡Œä¸ºåˆ†æ
    print("\nğŸ¯ 3. ç”¨æˆ·è¡Œä¸ºæ¨¡å¼åˆ†æ...")
    
    user_stats = []
    for user_id in df['user_id'].unique()[:8]:  # åˆ†æå‰8ä¸ªç”¨æˆ·
        user_df = df[df['user_id'] == user_id]
        
        # ç§»åŠ¨æ¨¡å¼
        positions = user_df[['pos_x', 'pos_y']].values
        if len(positions) > 1:
            distances = np.sqrt(np.sum(np.diff(positions, axis=0)**2, axis=1))
            total_distance = np.sum(distances)
            max_distance = np.max(distances) if len(distances) > 0 else 0
        else:
            total_distance = 0
            max_distance = 0
        
        # è¡Œä¸ºç‰¹å¾
        avg_usage = user_df['data_usage'].mean()
        preferred_slice = user_df['slice_type'].iloc[0]
        
        user_stats.append({
            'user_id': user_id,
            'total_movement': total_distance,
            'max_step': max_distance,
            'avg_data_usage': avg_usage,
            'preferred_slice': preferred_slice
        })
        
        print(f"   ğŸ“± {user_id}: ç§»åŠ¨è·ç¦» {total_distance:.1f}m, "
              f"æ•°æ®ä½¿ç”¨ {avg_usage:.1f}MB, åå¥½åˆ‡ç‰‡ {preferred_slice}")
    
    # 4. AIé¢„æµ‹æ¨¡æ‹Ÿ
    print("\nğŸ§  4. AIé¢„æµ‹ç®—æ³•æ¨¡æ‹Ÿ...")
    
    # æå–ç‰¹å¾
    latest_data = []
    unique_users = df['user_id'].unique()
    
    for user_id in unique_users:
        user_df = df[df['user_id'] == user_id].tail(10)  # æœ€è¿‘10ä¸ªæ•°æ®ç‚¹
        
        if len(user_df) >= 5:
            features = [
                user_df['pos_x'].mean(),
                user_df['pos_y'].mean(),
                user_df['data_usage'].mean(),
                user_df['signal_strength'].mean(),
                user_df['latency'].mean(),
                user_df['throughput'].mean(),
                user_df['data_usage'].std(),
                len(user_df)
            ]
            latest_data.append({
                'user_id': user_id,
                'features': features,
                'actual_slice': user_df['slice_type'].iloc[-1]
            })
    
    features_matrix = np.array([d['features'] for d in latest_data])
    print(f"   âœ… æå–äº† {len(latest_data)} ä¸ªç”¨æˆ·çš„ç‰¹å¾å‘é‡")
    
    # æ‰§è¡Œé¢„æµ‹
    predictions = simulate_ai_prediction(features_matrix)
    print(f"   ğŸ¯ é¢„æµ‹å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {np.mean(predictions['confidence']):.3f}")
    
    # 5. ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–
    print("\nâš¡ 5. ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–åˆ†é…...")
    
    # è·å–æ¯ä¸ªç”¨æˆ·çš„æœ€æ–°æ•°æ®
    user_latest = []
    for d in latest_data:
        user_data_point = [ud for ud in user_data if ud.user_id == d['user_id']][-1]
        user_latest.append(user_data_point)
    
    allocations = optimize_network_slices(predictions, user_latest)
    
    print(f"   âœ… å®Œæˆ {len(allocations)} ä¸ªç”¨æˆ·çš„åˆ‡ç‰‡åˆ†é…")
    
    # ç»Ÿè®¡ç»“æœ
    total_allocated = sum(a['allocated_bandwidth'] for a in allocations)
    print(f"   ğŸ“Š æ€»åˆ†é…å¸¦å®½: {total_allocated:.1f} Mbps / 1000 Mbps")
    print(f"   ğŸ“ˆ å¸¦å®½åˆ©ç”¨ç‡: {total_allocated/1000*100:.1f}%")
    
    # 6. ç»“æœåˆ†æ
    print("\nğŸ“‹ 6. ä¼˜åŒ–ç»“æœåˆ†æ...")
    
    # æŒ‰åˆ‡ç‰‡ç±»å‹ç»Ÿè®¡
    slice_stats = {}
    for alloc in allocations:
        slice_type = alloc['slice_type']
        if slice_type not in slice_stats:
            slice_stats[slice_type] = {'count': 0, 'bandwidth': 0, 'satisfaction': []}
        
        slice_stats[slice_type]['count'] += 1
        slice_stats[slice_type]['bandwidth'] += alloc['allocated_bandwidth']
        slice_stats[slice_type]['satisfaction'].append(alloc['satisfaction'])
    
    print("   ğŸ¯ æŒ‰åˆ‡ç‰‡ç±»å‹ç»Ÿè®¡:")
    for slice_type, stats in slice_stats.items():
        avg_satisfaction = np.mean(stats['satisfaction'])
        print(f"     â€¢ {slice_type}:")
        print(f"       - ç”¨æˆ·æ•°: {stats['count']}")
        print(f"       - æ€»å¸¦å®½: {stats['bandwidth']:.1f} Mbps")
        print(f"       - å¹³å‡æ»¡æ„åº¦: {avg_satisfaction:.3f}")
    
    # æ˜¾ç¤ºè¯¦ç»†åˆ†é…ç»“æœ
    print("\n   ğŸ“Š è¯¦ç»†åˆ†é…ç»“æœ(å‰10ä¸ªç”¨æˆ·):")
    for i, alloc in enumerate(allocations[:10]):
        print(f"     {i+1:2d}. {alloc['user_id']} | "
              f"{alloc['slice_type']:6s} | "
              f"åˆ†é…: {alloc['allocated_bandwidth']:6.1f} Mbps | "
              f"éœ€æ±‚: {alloc['demanded_bandwidth']:6.1f} Mbps | "
              f"æ»¡æ„åº¦: {alloc['satisfaction']:.3f}")
    
    # 7. æ€§èƒ½æŒ‡æ ‡
    print("\nâš¡ 7. ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡...")
    
    # æ€»ä½“æ»¡æ„åº¦
    avg_satisfaction = np.mean([a['satisfaction'] for a in allocations])
    print(f"   ğŸ“ˆ å¹³å‡ç”¨æˆ·æ»¡æ„åº¦: {avg_satisfaction*100:.1f}%")
    
    # é«˜ä¼˜å…ˆçº§ç”¨æˆ·æœåŠ¡è´¨é‡
    high_priority = [a for a in allocations if a['priority'] >= 3]
    if high_priority:
        hp_satisfaction = np.mean([a['satisfaction'] for a in high_priority])
        print(f"   ğŸ”¥ é«˜ä¼˜å…ˆçº§ç”¨æˆ·æ»¡æ„åº¦: {hp_satisfaction*100:.1f}%")
    
    # èµ„æºåˆ©ç”¨æ•ˆç‡
    bandwidth_efficiency = total_allocated / 1000.0
    print(f"   ğŸ’ª å¸¦å®½åˆ©ç”¨æ•ˆç‡: {bandwidth_efficiency*100:.1f}%")
    
    # é¢„æµ‹å‡†ç¡®æ€§ï¼ˆç®€åŒ–è¯„ä¼°ï¼‰
    correct_predictions = 0
    for i, alloc in enumerate(allocations):
        actual_slice = latest_data[i]['actual_slice']
        predicted_slice = alloc['slice_type']
        if actual_slice == predicted_slice:
            correct_predictions += 1
    
    accuracy = correct_predictions / len(allocations) if allocations else 0
    print(f"   ğŸ¯ åˆ‡ç‰‡é¢„æµ‹å‡†ç¡®ç‡: {accuracy*100:.1f}%")
    
    # 8. å¯¼å‡ºç»“æœ
    print("\nğŸ’¾ 8. å¯¼å‡ºæ¼”ç¤ºç»“æœ...")
    
    export_data = {
        'demo_info': {
            'timestamp': datetime.now().isoformat(),
            'total_users': len(unique_users),
            'total_data_points': len(user_data),
            'duration_hours': 2
        },
        'performance_metrics': {
            'bandwidth_utilization': bandwidth_efficiency,
            'average_satisfaction': avg_satisfaction,
            'prediction_accuracy': accuracy,
            'total_allocated_bandwidth': total_allocated
        },
        'slice_statistics': slice_stats,
        'sample_allocations': allocations[:10]  # ä¿å­˜å‰10ä¸ªç»“æœ
    }
    
    # ä¿å­˜ä¸ºJSONæ–‡ä»¶
    filename = f"standalone_demo_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"   âœ… ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
    
    # 9. æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ‰ ç‹¬ç«‹æ¼”ç¤ºå®Œæˆï¼")
    print("\nâœ¨ æ¼”ç¤ºç‰¹è‰²:")
    print("   ğŸ¯ å®Œå…¨ç‹¬ç«‹è¿è¡Œï¼Œæ— éœ€å¤æ‚ä¾èµ–")
    print("   ğŸ“Š çœŸå®çš„5Gç”¨æˆ·æ•°æ®æ¨¡æ‹Ÿ")
    print("   ğŸ§  AIé¢„æµ‹ç®—æ³•æ•ˆæœå±•ç¤º")
    print("   âš¡ æ™ºèƒ½ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–")
    print("   ğŸ“ˆ è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š")
    
    print(f"\nğŸ“Š æ ¸å¿ƒæŒ‡æ ‡:")
    print(f"   â€¢ å¤„ç†ç”¨æˆ·æ•°: {len(unique_users)}")
    print(f"   â€¢ å¸¦å®½åˆ©ç”¨ç‡: {bandwidth_efficiency*100:.1f}%")
    print(f"   â€¢ ç”¨æˆ·æ»¡æ„åº¦: {avg_satisfaction*100:.1f}%") 
    print(f"   â€¢ é¢„æµ‹å‡†ç¡®ç‡: {accuracy*100:.1f}%")
    
    print("\nğŸš€ å®Œæ•´ç‰ˆåŠŸèƒ½:")
    print("   â€¢ å®‰è£…PyTorchåå¯è¿è¡Œå®Œæ•´çš„Transformeræ¨¡å‹")
    print("   â€¢ æ”¯æŒæ¨¡å‹è®­ç»ƒå’Œå®æ—¶é¢„æµ‹")
    print("   â€¢ æä¾›Webå¯è§†åŒ–ä»ªè¡¨æ¿")
    
    return export_data


if __name__ == "__main__":
    try:
        result = run_standalone_demo()
        print(f"\nâœ… æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()