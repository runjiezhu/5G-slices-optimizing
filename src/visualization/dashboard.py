"""
Streamlitå¯è§†åŒ–ä»ªè¡¨æ¿
å®æ—¶ç›‘æ§5Gç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿçš„æ€§èƒ½å’Œé¢„æµ‹ç»“æœ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging

from ..prediction_engine.realtime_predictor import RealTimePredictionEngine, PredictionResult
from ..data_processing.data_generator import UserDataGenerator
from ..models.slice_optimizer import SliceType


class Dashboard:
    """5Gç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿä»ªè¡¨æ¿"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä»ªè¡¨æ¿"""
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'engine' not in st.session_state:
            st.session_state.engine = None
        if 'data_generator' not in st.session_state:
            st.session_state.data_generator = UserDataGenerator()
        if 'is_running' not in st.session_state:
            st.session_state.is_running = False
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []
    
    def run(self):
        """è¿è¡Œä»ªè¡¨æ¿"""
        st.set_page_config(
            page_title="5Gç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿ",
            page_icon="ğŸŒ",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # é¡µé¢æ ‡é¢˜
        st.title("ğŸŒ 5GåŠ¨æ€ç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿ")
        st.markdown("åŸºäºTransformeræ¶æ„çš„å®æ—¶é¢„æµ‹å’Œä¼˜åŒ–ç›‘æ§")
        
        # ä¾§è¾¹æ æ§åˆ¶
        self._render_sidebar()
        
        # ä¸»è¦å†…å®¹åŒºåŸŸ
        if st.session_state.engine is None:
            self._render_welcome()
        else:
            self._render_main_dashboard()
    
    def _render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.header("ğŸ”§ ç³»ç»Ÿæ§åˆ¶")
        
        # ç³»ç»Ÿå¯åŠ¨/åœæ­¢
        if st.sidebar.button("ğŸš€ å¯åŠ¨ç³»ç»Ÿ" if not st.session_state.is_running else "â¹ï¸ åœæ­¢ç³»ç»Ÿ"):
            if not st.session_state.is_running:
                self._start_system()
            else:
                self._stop_system()
        
        st.sidebar.divider()
        
        # æ•°æ®ç”Ÿæˆæ§åˆ¶
        st.sidebar.subheader("ğŸ“Š æ•°æ®ç”Ÿæˆ")
        
        num_users = st.sidebar.slider("ç”¨æˆ·æ•°é‡", 5, 50, 20, 5)
        duration = st.sidebar.slider("æŒç»­æ—¶é—´(å°æ—¶)", 1, 24, 2, 1)
        
        if st.sidebar.button("ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"):
            self._generate_simulation_data(num_users, duration)
        
        st.sidebar.divider()
        
        # ç³»ç»Ÿé…ç½®
        st.sidebar.subheader("âš™ï¸ ç³»ç»Ÿé…ç½®")
        
        refresh_rate = st.sidebar.selectbox(
            "åˆ·æ–°ç‡(ç§’)",
            [1, 2, 5, 10],
            index=1
        )
        
        confidence_threshold = st.sidebar.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            0.0, 1.0, 0.8, 0.1
        )
        
        # æ˜¾ç¤ºé€‰é¡¹
        st.sidebar.subheader("ğŸ“ˆ æ˜¾ç¤ºé€‰é¡¹")
        
        show_real_time = st.sidebar.checkbox("å®æ—¶æ›´æ–°", True)
        show_predictions = st.sidebar.checkbox("é¢„æµ‹ç»“æœ", True)
        show_slice_info = st.sidebar.checkbox("åˆ‡ç‰‡ä¿¡æ¯", True)
        show_performance = st.sidebar.checkbox("æ€§èƒ½ç›‘æ§", True)
        
        # å°†é…ç½®å­˜å‚¨åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.refresh_rate = refresh_rate
        st.session_state.confidence_threshold = confidence_threshold
        st.session_state.show_real_time = show_real_time
        st.session_state.show_predictions = show_predictions
        st.session_state.show_slice_info = show_slice_info
        st.session_state.show_performance = show_performance
    
    def _render_welcome(self):
        """æ¸²æŸ“æ¬¢è¿é¡µé¢"""
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            st.markdown("""
            ## ğŸ¯ æ¬¢è¿ä½¿ç”¨5Gç½‘ç»œåˆ‡ç‰‡ä¼˜åŒ–ç³»ç»Ÿ
            
            ### ç³»ç»Ÿç‰¹è‰²ï¼š
            - ğŸ§  **Transformeræ¶æ„**: å…ˆè¿›çš„æ—¶é—´åºåˆ—é¢„æµ‹
            - ğŸ“± **å®æ—¶å¤„ç†**: æ¯«ç§’çº§é¢„æµ‹å“åº”
            - ğŸ”§ **æ™ºèƒ½åˆ‡ç‰‡**: è‡ªé€‚åº”èµ„æºåˆ†é…
            - ğŸ“Š **æ•°æ®é©±åŠ¨**: åŸºäºç”¨æˆ·è¡Œä¸ºçš„ä¼˜åŒ–
            
            ### å¼€å§‹ä½¿ç”¨ï¼š
            1. ç‚¹å‡»ä¾§è¾¹æ çš„ "ğŸš€ å¯åŠ¨ç³»ç»Ÿ" æŒ‰é’®
            2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
            3. è§‚å¯Ÿå®æ—¶é¢„æµ‹ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
            
            ### ç½‘ç»œåˆ‡ç‰‡ç±»å‹ï¼š
            - **eMBB**: å¢å¼ºå‹ç§»åŠ¨å®½å¸¦ (é«˜å¸¦å®½)
            - **URLLC**: è¶…å¯é ä½æ—¶å»¶é€šä¿¡ (ä½å»¶è¿Ÿ)
            - **mMTC**: å¤§è§„æ¨¡æœºå™¨ç±»å‹é€šä¿¡ (å¤§è¿æ¥)
            """)
            
            # ç³»ç»Ÿæ¶æ„å›¾
            st.markdown("### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„")
            
            # åˆ›å»ºç®€åŒ–çš„æ¶æ„å›¾
            fig = go.Figure()
            
            # æ·»åŠ æ¶æ„ç»„ä»¶
            components = [
                {"name": "ç”¨æˆ·æ•°æ®", "x": 1, "y": 3, "color": "#FF6B6B"},
                {"name": "æ•°æ®å¤„ç†", "x": 2, "y": 3, "color": "#4ECDC4"},
                {"name": "Transformer\né¢„æµ‹å™¨", "x": 3, "y": 3, "color": "#45B7D1"},
                {"name": "åˆ‡ç‰‡ä¼˜åŒ–å™¨", "x": 4, "y": 3, "color": "#96CEB4"},
                {"name": "å®æ—¶ç›‘æ§", "x": 3, "y": 2, "color": "#FFEAA7"}
            ]
            
            for comp in components:
                fig.add_trace(go.Scatter(
                    x=[comp["x"]],
                    y=[comp["y"]],
                    mode='markers+text',
                    marker=dict(size=60, color=comp["color"]),
                    text=comp["name"],
                    textposition="middle center",
                    showlegend=False
                ))
            
            # æ·»åŠ è¿æ¥çº¿
            connections = [
                (1, 3, 2, 3), (2, 3, 3, 3), (3, 3, 4, 3), (3, 3, 3, 2)
            ]
            
            for x1, y1, x2, y2 in connections:
                fig.add_trace(go.Scatter(
                    x=[x1, x2],
                    y=[y1, y2],
                    mode='lines',
                    line=dict(color='gray', width=2),
                    showlegend=False,
                    hoverinfo='skip'
                ))
            
            fig.update_layout(
                showlegend=False,
                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                height=300,
                margin=dict(l=0, r=0, t=0, b=0)
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_main_dashboard(self):
        """æ¸²æŸ“ä¸»ä»ªè¡¨æ¿"""
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        self._render_status_indicators()
        
        # å®æ—¶æ•°æ®
        if st.session_state.show_real_time:
            self._render_real_time_metrics()
        
        # é¢„æµ‹ç»“æœ
        if st.session_state.show_predictions:
            self._render_prediction_results()
        
        # åˆ‡ç‰‡ä¿¡æ¯
        if st.session_state.show_slice_info:
            self._render_slice_information()
        
        # æ€§èƒ½ç›‘æ§
        if st.session_state.show_performance:
            self._render_performance_monitoring()
        
        # è‡ªåŠ¨åˆ·æ–°
        if st.session_state.show_real_time:
            time.sleep(st.session_state.refresh_rate)
            st.rerun()
    
    def _render_status_indicators(self):
        """æ¸²æŸ“çŠ¶æ€æŒ‡ç¤ºå™¨"""
        st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        if st.session_state.engine:
            status = st.session_state.engine.get_system_status()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ç³»ç»ŸçŠ¶æ€",
                    "ğŸŸ¢ è¿è¡Œä¸­" if status.is_running else "ğŸ”´ å·²åœæ­¢",
                    delta=None
                )
            
            with col2:
                st.metric(
                    "æ´»è·ƒç”¨æˆ·",
                    status.active_users,
                    delta=None
                )
            
            with col3:
                st.metric(
                    "æ€»é¢„æµ‹æ•°",
                    status.total_predictions,
                    delta=None
                )
            
            with col4:
                st.metric(
                    "å¹³å‡å»¶è¿Ÿ",
                    f"{status.average_latency:.3f}s",
                    delta=None
                )
    
    def _render_real_time_metrics(self):
        """æ¸²æŸ“å®æ—¶æŒ‡æ ‡"""
        st.subheader("ğŸ“ˆ å®æ—¶æŒ‡æ ‡")
        
        if st.session_state.engine:
            # è·å–æœ€æ–°é¢„æµ‹ç»“æœ
            recent_predictions = st.session_state.engine.get_latest_predictions(limit=20)
            
            if recent_predictions:
                # å‡†å¤‡æ•°æ®
                df_predictions = []
                for pred in recent_predictions:
                    df_predictions.append({
                        'timestamp': pred.timestamp,
                        'user_id': pred.user_id,
                        'confidence': pred.confidence_score,
                        'processing_time': pred.processing_time,
                        'slice_count': len(pred.slice_allocations)
                    })
                
                df = pd.DataFrame(df_predictions)
                
                # åˆ›å»ºå®æ—¶å›¾è¡¨
                col1, col2 = st.columns(2)
                
                with col1:
                    # ç½®ä¿¡åº¦è¶‹åŠ¿
                    fig_confidence = px.line(
                        df, x='timestamp', y='confidence',
                        title='é¢„æµ‹ç½®ä¿¡åº¦è¶‹åŠ¿',
                        labels={'confidence': 'ç½®ä¿¡åº¦', 'timestamp': 'æ—¶é—´'}
                    )
                    fig_confidence.update_layout(height=300)
                    st.plotly_chart(fig_confidence, use_container_width=True)
                
                with col2:
                    # å¤„ç†æ—¶é—´åˆ†å¸ƒ
                    fig_time = px.histogram(
                        df, x='processing_time',
                        title='é¢„æµ‹å¤„ç†æ—¶é—´åˆ†å¸ƒ',
                        labels={'processing_time': 'å¤„ç†æ—¶é—´(ç§’)', 'count': 'é¢‘æ¬¡'}
                    )
                    fig_time.update_layout(height=300)
                    st.plotly_chart(fig_time, use_container_width=True)
    
    def _render_prediction_results(self):
        """æ¸²æŸ“é¢„æµ‹ç»“æœ"""
        st.subheader("ğŸ¯ é¢„æµ‹ç»“æœ")
        
        if st.session_state.engine:
            recent_predictions = st.session_state.engine.get_latest_predictions(limit=10)
            
            if recent_predictions:
                # åˆ›å»ºç»“æœè¡¨æ ¼
                results_data = []
                for pred in recent_predictions:
                    slice_types = [alloc.slice_type.name for alloc in pred.slice_allocations]
                    total_bandwidth = sum(alloc.allocated_bandwidth for alloc in pred.slice_allocations)
                    
                    results_data.append({
                        'æ—¶é—´': pred.timestamp.strftime('%H:%M:%S'),
                        'ç”¨æˆ·ID': pred.user_id,
                        'ç½®ä¿¡åº¦': f"{pred.confidence_score:.3f}",
                        'åˆ‡ç‰‡ç±»å‹': ', '.join(slice_types) if slice_types else 'None',
                        'æ€»å¸¦å®½(Mbps)': f"{total_bandwidth:.1f}",
                        'å¤„ç†æ—¶é—´(ms)': f"{pred.processing_time*1000:.1f}"
                    })
                
                df_results = pd.DataFrame(results_data)
                st.dataframe(df_results, use_container_width=True)
                
                # åˆ‡ç‰‡ç±»å‹åˆ†å¸ƒé¥¼å›¾
                if results_data:
                    slice_counts = {}
                    for pred in recent_predictions:
                        for alloc in pred.slice_allocations:
                            slice_type = alloc.slice_type.name
                            slice_counts[slice_type] = slice_counts.get(slice_type, 0) + 1
                    
                    if slice_counts:
                        fig_pie = px.pie(
                            values=list(slice_counts.values()),
                            names=list(slice_counts.keys()),
                            title='åˆ‡ç‰‡ç±»å‹åˆ†å¸ƒ'
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)
    
    def _render_slice_information(self):
        """æ¸²æŸ“åˆ‡ç‰‡ä¿¡æ¯"""
        st.subheader("ğŸ”§ ç½‘ç»œåˆ‡ç‰‡ä¿¡æ¯")
        
        # åˆ‡ç‰‡ç±»å‹è¯´æ˜
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            ### eMBB (å¢å¼ºå‹ç§»åŠ¨å®½å¸¦)
            - ğŸ¯ **ç›®æ ‡**: é«˜å¸¦å®½åº”ç”¨
            - ğŸ“± **åº”ç”¨**: è§†é¢‘æµã€æ–‡ä»¶ä¸‹è½½
            - ğŸš€ **å¸¦å®½**: 10-1000 Mbps
            - â±ï¸ **å»¶è¿Ÿ**: â‰¤20ms
            - ğŸšï¸ **ä¼˜å…ˆçº§**: 1 (ä½)
            """)
        
        with col2:
            st.markdown("""
            ### URLLC (è¶…å¯é ä½æ—¶å»¶é€šä¿¡)
            - ğŸ¯ **ç›®æ ‡**: è¶…ä½å»¶è¿Ÿ
            - ğŸš— **åº”ç”¨**: è‡ªåŠ¨é©¾é©¶ã€å·¥ä¸šæ§åˆ¶
            - ğŸš€ **å¸¦å®½**: 1-50 Mbps
            - â±ï¸ **å»¶è¿Ÿ**: â‰¤1ms
            - ğŸšï¸ **ä¼˜å…ˆçº§**: 3 (é«˜)
            """)
        
        with col3:
            st.markdown("""
            ### mMTC (å¤§è§„æ¨¡æœºå™¨ç±»å‹é€šä¿¡)
            - ğŸ¯ **ç›®æ ‡**: å¤§è¿æ¥æ•°
            - ğŸŒ **åº”ç”¨**: IoTè®¾å¤‡ã€ä¼ æ„Ÿå™¨
            - ğŸš€ **å¸¦å®½**: 0.1-10 Mbps
            - â±ï¸ **å»¶è¿Ÿ**: â‰¤100ms
            - ğŸšï¸ **ä¼˜å…ˆçº§**: 2 (ä¸­)
            """)
        
        # ç½‘ç»œèµ„æºçŠ¶æ€
        if st.session_state.engine:
            resources = st.session_state.engine.network_resources
            
            st.markdown("### ğŸ“Š ç½‘ç»œèµ„æºçŠ¶æ€")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»å¸¦å®½", f"{resources.total_bandwidth:.0f} Mbps")
            
            with col2:
                st.metric("å¯ç”¨å¸¦å®½", f"{resources.available_bandwidth:.0f} Mbps")
            
            with col3:
                st.metric("CPUä½¿ç”¨ç‡", f"{resources.cpu_usage*100:.1f}%")
            
            with col4:
                st.metric("å†…å­˜ä½¿ç”¨ç‡", f"{resources.memory_usage*100:.1f}%")
    
    def _render_performance_monitoring(self):
        """æ¸²æŸ“æ€§èƒ½ç›‘æ§"""
        st.subheader("âš¡ æ€§èƒ½ç›‘æ§")
        
        if st.session_state.engine:
            # è·å–æ€§èƒ½ç»Ÿè®¡
            perf_stats = st.session_state.engine.predictor.get_performance_stats()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ğŸ“Š é¢„æµ‹æ€§èƒ½")
                metrics = perf_stats['prediction_metrics']
                
                st.metric("æ€»é¢„æµ‹æ¬¡æ•°", metrics['total_predictions'])
                st.metric("å¹³å‡å»¶è¿Ÿ", f"{metrics['avg_latency']*1000:.1f} ms")
                st.metric("ç¼“å†²åŒºå¤§å°", perf_stats['buffer_size'])
                st.metric("ç¼“å­˜å¤§å°", perf_stats['cache_size'])
            
            with col2:
                st.markdown("### ğŸ¯ ç³»ç»ŸçŠ¶æ€")
                st.metric("é¢„æµ‹å†å²", perf_stats['prediction_history_size'])
                st.metric("è¿è¡Œè®¾å¤‡", perf_stats['model_device'])
                st.metric(
                    "æ¨¡å‹çŠ¶æ€", 
                    "âœ… å·²è®­ç»ƒ" if perf_stats['is_trained'] else "âŒ æœªè®­ç»ƒ"
                )
                
                # å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆæ¨¡æ‹Ÿï¼‰
                import psutil
                memory_percent = psutil.virtual_memory().percent
                st.metric("ç³»ç»Ÿå†…å­˜", f"{memory_percent:.1f}%")
    
    def _start_system(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        try:
            st.session_state.engine = RealTimePredictionEngine()
            st.session_state.engine.start()
            st.session_state.is_running = True
            st.success("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸï¼")
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
    
    def _stop_system(self):
        """åœæ­¢ç³»ç»Ÿ"""
        try:
            if st.session_state.engine:
                st.session_state.engine.stop()
                st.session_state.engine = None
            st.session_state.is_running = False
            st.success("âœ… ç³»ç»Ÿå·²åœæ­¢ï¼")
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ç³»ç»Ÿåœæ­¢å¤±è´¥: {e}")
    
    def _generate_simulation_data(self, num_users: int, duration: int):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        if not st.session_state.engine:
            st.error("âŒ è¯·å…ˆå¯åŠ¨ç³»ç»Ÿï¼")
            return
        
        try:
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®..."):
                # ç”Ÿæˆæ•°æ®
                user_data = st.session_state.data_generator.generate_dataset(
                    num_users=num_users,
                    duration_hours=duration,
                    sampling_interval=60
                )
                
                # æ·»åŠ åˆ°å¼•æ“
                st.session_state.engine.batch_add_data(user_data)
                
                st.success(f"âœ… å·²ç”Ÿæˆ {len(user_data)} æ¡æ•°æ®è®°å½•ï¼")
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç³»ç»Ÿå¤„ç†
                time.sleep(2)
                st.rerun()
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    dashboard = Dashboard()
    dashboard.run()


if __name__ == "__main__":
    main()